#!/usr/bin/env python
import os
import md5
import time
import magic
import requests
import argparse


class Malware:
    def __init__(self, path, timeout, verbose):
        self.path = path
        self.timeout = timeout
        self.verbose = verbose
        self.magic = magic.open(magic.MAGIC_NONE)
        self.magic.load()
        try:os.makedirs(path)
        except OSError:pass
        if not os.path.exists('%s/log' % path):
            f = open('%s/log' % path, 'w+')
            f.close()

    def scrape(self):
        try:self._save(list(self._malwaredl()), 'www.malwaredomainlist.com')
        except Exception as e: print '[ERROR] www.malwaredomainlist.com\n%s' % e
        try:self._save(list(self._minotaur()), 'www.minotauranalysis.com')
        except Exception as e: print '[ERROR] www.minotauranalysis.com\n %s' % e
        try:self._save(list(self._vxvault()), 'www.vxvault.siri.urz.net')
        except Exception as e: print '[ERROR] www.vxvault.siri.urz.net\n %s' % e
        try:self._save(list(self._malcode()), 'www.malcOde.com')
        except Exception as e: print '[ERROR] www.malc0de.com\n %s' % e
        try:self._save(list(self._malwarebl()), 'www.malwareblacklist.com')
        except Exception as e: print '[ERROR] www.malwareblacklist.com'
        try:self._save(list(self._sacour()), 'www.sacour.cn')
        except Exception as e: print '[ERROR] www.sacour.cn'

    def _save(self, items, url):
        l = open('%s/log' % self.path, 'a')
        print 'found %s items on %s' % (len(items), url)
        for item in items:
            try:
                download = requests.get(item['link'], timeout=self.timeout)
                mhash = md5.new(download.content).hexdigest()
                ftype = self.magic.buffer(download.content).split(' ')[0].lower()
            except Exception as e: continue
            if self.verbose is True:
                print '[DOWNLOADED] %s' % item['link'][:60]
            description = item['description'].replace(' ', '_').replace('.', '_')
            description = description.replace(':', '_').replace('/', '_')
            description = '_'.join(description.split('_')[:2])
            dpath = '%s/%s/%s' % (self.path, ftype, description)
            if not os.path.exists(dpath):
                os.makedirs(dpath)
            if not os.path.exists('%s/%s' % (dpath, mhash)):
                    f = open('%s/%s' % (dpath, mhash), 'w+')
                    f.write(download.content)
                    f.close()
                    l.write('%s,%s,%s,%s,%s\n' % (
                        item['date'], item['link'], item['country'], mhash, description))
        l.close()

    def _malwaredl(self):
        http = requests.get('http://www.malwaredomainlist.com/hostslist/mdl.xml', timeout=self.timeout)
        for item in http.content.split('<title>'):
            try:
                link = item.split('Host: ')[1].split(',')[0]
                if link is '-':
                    link =  item.split('IP address: ')[1].split(',')[0]
                description = item.split('Description: ')[1].split('</description>')[0]
                country = item.split('Country: ')[1].split(',')[0]
                date = item.split(' (')[1].split(')</title>')[0]
                yield {'link':'http://%s' % link,
                       'description':description,
                       'country':country,
                       'date':date}
            except IndexError: pass
            except Exception as e: print '[Error] %s' % e


    def _minotaur(self):
        pass
        ##### currently broken #####
        #'http://minotauranalysis.com/malwarelist-urls.aspx'

    def _vxvault(self):
        http = requests.get('http://vxvault.siri-urz.net/URL_List.php', timeout=self.timeout)
        for line in http.content.split('\n'):
            if line.startswith('http://'):
                yield {'link':line,
                    'description':'unkown',
                    'country':'unkown',
                    'date':time.strftime('%c')}

    def _malcode(self):
        http = requests.get('http://malc0de.com/rss', timeout=self.timeout)
        for item in http.content.split('<title>'):
            try:
                link = item.split('URL: ')[1].split(',')[0]
                country = item.split('Country: ')[1].split(',')[0]
                yield {'link':link,
                       'description':'unknown',
                       'country':country,
                       'date':time.strftime('%c')}
            except IndexError: pass
            except Exception as e: print '[Error] %s' % e

    def _malwarebl(self):
        pass
        ##### currently broken #####
        #'http://www.malwareblacklist.com/mbl.xml'

    def _sacour(self):
        pass
        ##### currently broken #####
        #'http://www.sacour.cn/showmal.asp?month=%d&year=%d'


if __name__ == '__main__':
    parse = argparse.ArgumentParser()
    parse.add_argument('path', help='dir path to save output')
    parse.add_argument('-v', help='verbose', action='store_true')
    parse.add_argument('-t', metavar=('time'),
        help='timeout (DEFAULT: 5)', default=5)
    args = parse.parse_args()
    malware = Malware(args.path, args.t, args.v)
    malware.scrape()
